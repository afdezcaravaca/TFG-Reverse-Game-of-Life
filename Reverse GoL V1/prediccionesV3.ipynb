{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71e578d9",
   "metadata": {},
   "source": [
    "### <ins> Predicciones: Modelo &delta; = 1 </ins>\n",
    "\n",
    "Vamos a usar el modelo asociado a $\\delta$ = 1 para predecir todos los tableros, independientemente del número de pasos que haya entre medias. Para ello, vamos a utilizar este modelo tantas veces como pasos haya entre el tablero inicial y final.\n",
    "\n",
    "No es un modelo nuevo como tal, pues tan solo estoy usando el modelo que mejor resultados me está dando repetidamente para predecir tableros. Sin embargo, como es otro approach, pues voy a considerarlo aparte.\n",
    "\n",
    "**1. Importar librerías, definimos las funciones de as métricas y modelos:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26e85ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "# 1. Define la semilla\n",
    "SEED = 42  # Según ChatGPT es la mejor\n",
    " \n",
    "# 2. Python built-in random\n",
    "random.seed(SEED)\n",
    "\n",
    "# 3. NumPy\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# 4. TensorFlow\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# (Opcional) Para TensorFlow más determinismo en operaciones GPU:\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "    tp = K.sum(y_true * y_pred_pos)\n",
    "    possible_positives = K.sum(y_true)\n",
    "    return tp / (possible_positives + K.epsilon())\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "    tp = K.sum(y_true * y_pred_pos)\n",
    "    predicted_positives = K.sum(y_pred_pos)\n",
    "    return tp / (predicted_positives + K.epsilon())\n",
    "\n",
    "def f1_score_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2 * (precision * recall) / (precision + recall + K.epsilon())\n",
    "\n",
    "def specificity_m(y_true, y_pred):\n",
    "    y_pred_neg = 1 - K.round(K.clip(y_pred, 0, 1))\n",
    "    y_true_neg = 1 - y_true\n",
    "    tn = K.sum(y_true_neg * y_pred_neg)\n",
    "    possible_negatives = K.sum(y_true_neg)\n",
    "    return tn / (possible_negatives + K.epsilon())\n",
    "\n",
    "def hamming_loss_m(y_true, y_pred):\n",
    "    # Fracción de etiquetas incorrectas\n",
    "    mismatches = K.not_equal(K.round(K.clip(y_pred, 0, 1)), y_true)\n",
    "    return K.mean(K.cast(mismatches, K.floatx()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04d269d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../Datos\\\\test.xlsx', '../Datos\\\\train.xlsx']\n"
     ]
    }
   ],
   "source": [
    "path = 'modelo_delta1'\n",
    "modelo1 = load_model(\n",
    "        path, \n",
    "        compile=False, \n",
    "        custom_objects={\n",
    "            'accuracy': tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "            'recall_m': recall_m,\n",
    "            'precision_m': precision_m,\n",
    "            'f1_score_m': f1_score_m,\n",
    "            'specificity_m': specificity_m,\n",
    "            'hamming_loss_m': hamming_loss_m})\n",
    "\n",
    "# Buscamos los paths a todos los excels relevantes:\n",
    "path = \"../Datos\"\n",
    "datos = []\n",
    "for dirnames,_,filenames in os.walk(path):\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('.xlsx'):\n",
    "            datos.append(os.path.join(dirnames,filename))\n",
    "\n",
    "# Cargamos los datos del test:\n",
    "\n",
    "test = pd.read_excel((datos[0]), sheet_name = 'test', header = 0)\n",
    "stops = [f'stop.{i}' for i in range(1,401)]\n",
    "\n",
    "print(datos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c7d575",
   "metadata": {},
   "source": [
    "#### 2. **Hacemos las predicciones:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8b9269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "δ = 1\n",
      "312/312 [==============================] - 27s 67ms/step\n",
      "------------------------------------------------------------------\n",
      "δ = 2\n",
      "315/315 [==============================] - 21s 67ms/step\n",
      "315/315 [==============================] - 21s 68ms/step\n",
      "------------------------------------------------------------------\n",
      "δ = 3\n",
      "313/313 [==============================] - 21s 68ms/step\n",
      "313/313 [==============================] - 21s 67ms/step\n",
      "313/313 [==============================] - 21s 67ms/step\n",
      "------------------------------------------------------------------\n",
      "δ = 4\n",
      "307/307 [==============================] - 21s 69ms/step\n",
      "307/307 [==============================] - 21s 69ms/step\n",
      "307/307 [==============================] - 21s 69ms/step\n",
      "307/307 [==============================] - 21s 68ms/step\n",
      "------------------------------------------------------------------\n",
      "δ = 5\n",
      "318/318 [==============================] - 21s 67ms/step\n",
      "318/318 [==============================] - 21s 67ms/step\n",
      "318/318 [==============================] - 22s 68ms/step\n",
      "318/318 [==============================] - 23s 72ms/step\n",
      "318/318 [==============================] - 23s 72ms/step\n",
      "------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "archivo_excel = \"predicciones.xlsx\"\n",
    "with pd.ExcelWriter(archivo_excel, engine='openpyxl') as writer:\n",
    "    for delta in range(1, 6):\n",
    "        print(f'δ = {delta}')\n",
    "\n",
    "        # Filtro los datos y los preparo\n",
    "        delta_i = test[test['delta'] == delta]\n",
    "        finales_i = delta_i[stops].values.reshape(-1, 20, 20, 1, order='F')\n",
    "\n",
    "        # Aplico las predicciones en cadena\n",
    "        for _ in range(delta):\n",
    "            finales_i = modelo1.predict(finales_i)\n",
    "\n",
    "        # Reduzco el array final a filas (1 fila = 1 imagen aplanada de 20x20)\n",
    "        predicciones = finales_i.reshape(-1, 400).round().astype(np.uint8)\n",
    "\n",
    "        # Guardo directamente en Excel\n",
    "        pd.DataFrame(predicciones).to_excel(writer, sheet_name=f\"delta_{delta}\", index=False)\n",
    "        print('------------------------------------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfg_3.9",
   "language": "python",
   "name": "tfg_3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
